{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings to Study Gender and Ethnic Stereotypes in Popular American Film Dialogue\n",
    "\n",
    "### Background\n",
    "\n",
    "In their paper '[Word embeddings quantify 100 years of gender and ethnic stereotypes](https://www.pnas.org/doi/10.1073/pnas.1720347115),' authors Nikhil Garg, Londa Schiebinger, Dan Jurafsky, and James Zoue build a framework for measuring the \"changes in stereotypes and attitudes toward women and ethnic minorities in the 20th and 21st centuries in the United States\" using word embeddings or the relationship between words corresponding to gender or ethnic minorities and words associated with stereotypes or occupation.\"\n",
    "\n",
    "Their research uses three existing corpora of word vectors:\n",
    "\n",
    "1. [Google News, word2vec](https://code.google.com/archive/p/word2vec/)\n",
    "2. [Genre-Balanced American English (1830s-2000s), SGNS and SVD](https://nlp.stanford.edu/projects/histwords/)\n",
    "3. [Wikipedia, GloVe](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "As well they have tools and utilites to build word vectors as they did for [The New York Times Annotated Corpus](https://catalog.ldc.upenn.edu/LDC2008T19).\n",
    "\n",
    "They then collated several word lists to represent each gender (men, women) and ethnicity (White, Asian, and Hispanic), as well as neutral words (adjectives and occupations). Occupation data comes from [US Census Data](https://www.ipums.org/projects/ipums-usa/d010.v6.0) to extract the percentage of workers in each occupation that belong to each gender or ethnic group and compare it to the bias in the embeddings.\n",
    "\n",
    "Using these data the authors were able to compare word embedding biases toward for example occupations of women to historical data trends of women in particular occupations. These studies were reproduced across various corpora of word vectors to confirm their validity. Similar analyses were done using adjective stereotypes gleaned from historical surveys. The work was able to successfully \"illuminate how specific adjectives and occupations became more closely associated with certain populations over time.\"\n",
    "\n",
    "Using the utilities and word lists developed in this study I hope to answer whether we see similar evolving semantic relationships in occupation and adjective associations in the dialogue of popular American films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sources\n",
    "\n",
    "The previous study recognizes the derth of available historical datasets that attempt to quantify stereotypes for both gender and ethnicity. As well they use workers from Amazon's Mechanical Turk (AMT) to tag gender stereotypes of occupations, which may have limitations due to the AMT workers' contextual biases. \n",
    "\n",
    "The authors' study has a [Github Repository](https://github.com/nikhgarg/EmbeddingDynamicStereotypes) from which I hope to re-empoly various word lists as well as tools to generate a word vector corpus from movie subtitle data.\n",
    "\n",
    "Movie subtitles are publicly available to most American films in English having been created through a crowdsourcing process. Individuals generate 'SRT' files – text files which contain structured timecode data and dialogue text – through a variety of automated and by-hand processes. Most files are then published to [OpenSubtitles.org](https://www.opensubtitles.org/) which hosts subtitle files for films in dozens of different languages. Issues of concern include irregular structure of text file syntax to indictate 'sounds-on-tape' – music, sound effect description, etc. versus dialogue texts. As well there is a bias toward only the most popular films in American history and the populations that consume them which skews the available set of SRT files. This will likely also be the case for film lists found on Wikipedia which skew toward the popular as well.\n",
    "\n",
    "Using the Open Subtitle API and film list data crawled from Wikipedia entries, SRT files may be automatically downloaded and subsequently processed as was done in my brief study [Investigating Dialogue in Top Ten American Films](https://github.com/mbransons/vocab_in_film_dialogue). There is some potential to avoid using this combersome process and work with a [corpus of Open Subtitle data](https://opus.nlpl.eu/OpenSubtitles-v2018.php) created in 2016 by researchers Pierre Lison and Jorg Tiedemann as presented in their paper [OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles](http://www.lrec-conf.org/proceedings/lrec2016/pdf/947_Paper.pdf). Limitations of this dataset needs to be studied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Similar word embedding analyses will hopefully be possible if workable corpus of film dialogue word vectors can be created. In the event of difficulty, I can perform an analysis using a more limited set of SRT data.\n",
    "\n",
    "There is also the potential to look at an alternative analysis of dialogue by connecting the lines of dialogue to particular actors. There is a real gap in the data as dialogue texts are only connected to timecode stamps to assign the moment it should appear on the screen. But if texts can be reassigned to characters that speak them, then different approaches to gender and ethnic minorities studies can be undertaken. \n",
    "\n",
    "There's no automated way to generate such a dataset, though it may be possible to pilot a sample study with a handfull of SRT files looking at particular actors' characters across periods of time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
